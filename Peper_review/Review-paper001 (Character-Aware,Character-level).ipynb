{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:100px;text-align:center;border: 4px solid black;background-color:#4D0033;color:white\">\n",
    "\n",
    "<header style=\"width:100%;height:100px;\">\n",
    "  <h1><b> Chapter 001</b></h1>\n",
    "    <h4> Review Paper </h4>\n",
    "</header>\n",
    "\n",
    "<div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='border: 4px solid #4D0033;padding:9px;'>\n",
    "\n",
    "By: Farhad Shadmand \n",
    "    \n",
    "https://github.com/farhadsh1992\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #4D0033;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "        \n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:25%;height:40px;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4> contents-Paper:  </h4>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:#4D0033;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"A\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> Character-Aware Neural Language Models  </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:#4D0033;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"B\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> Character-level Convolutional Networks for Text Classification  </a></h6>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #4D0033;background-color:#158000;color:black;border-radius: 5px;padding:7px;color:white;\">\n",
    "  <strong> Summary: </strong><br>\n",
    "        \n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:70px;border: 4px solid black;background-color:#4D0033;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h1>   <h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:40px;border: 4px solid black;background-color:#1E00B3;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4>   </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:40px;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4>   </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"A\" style=\"width:100%;height:70px;border: 4px solid black;background-color:#8800CC;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h3>  Character-Aware Neural Language Models  </h3>\n",
    "    <h5>  2015, Yoon Kim   </h5>\n",
    "</div>/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #4D0033;background-color:#00404D;color:black;border-radius: 5px;padding:7px;color:white;\">\n",
    "  <strong> Summary: </strong><br>\n",
    "        \n",
    "A Language Model is formalised as a probability distribution over a sequence of string (words).  \n",
    "    \n",
    "1. Fisrt part of model is a  character-level convolutional neural network (CharCNN).\n",
    "    \n",
    "    \n",
    "The Model is disgined singluar-Layer charcter-level convolutional nernual network with max-over-time pooling.    \n",
    "    \n",
    "This model takes the ouput from singluar-Layer charcter-level convolutional nernual network with max-over-time pooling\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #8800CC;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "    \n",
    "(1) https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwjZs9Whp9fhAhX_QxUIHeXkC1MQFjAAegQIAxAB&url=https%3A%2F%2Farxiv.org%2Fabs%2F1508.06615&usg=AOvVaw2T-9s4pYuZ5e8VJhZR8n-S\n",
    "    \n",
    "(2)\n",
    "\n",
    "(3) Code: https://github.com/yoonkim/lstm-char-cnn    \n",
    "    \n",
    "Describe paper: https://www.youtube.com/watch?v=nzSPZyjGlWI\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:50%;height:40px;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4> Abstract:  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Language model is formalised as a probability distribution over a sequence of string (words ).<br>\n",
    "- Neural Language Models (NLM) address the n-gram data sparsity issue through parameterisation of words as vectors (word embeddings) and using them as inputs to a neural network.  <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Their model employs convolutional Neural Network (CNN) and a highway network over characters** which is used directly to predict word level.<br>\n",
    "\n",
    "## Note:\n",
    "- NLMs are blind to **subword information (morphemes)**.  For example,  They don’t know , a priori , that eventful, eventfully, uneventfully and uneventfully should have structurally related embeddings in the vector space.<br>\n",
    "- Their model does not require morphological tagging as a pre-processing step. \n",
    "- The Model takes **the output from a single-layer character-level convolution neural network with mix-over-time pooling**.\n",
    "- Thier  model doesn't need morphological tagging as pre-processing step. \n",
    "- the proposed model has significantly fewer parameters than previous NLMs, making it attractive for applications where model size may be an issue\n",
    "\n",
    "**Figure 1** (Architecture of the Model) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:50%;height:40px;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4> Architecture of the Model:  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Some Convulational Netwrok Language model takes words embedding as input.<br>\n",
    "**This model instead takes the ouput from singluar-Layer charcter-level convolutional nernual network with max-over-time pooling**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height:110px;\">\n",
    "<div style=\"height:30%;\">\n",
    "    \n",
    "<div style=\"width:400px; border:3px solid #B35900;position: absolute;left:9px;text-align: center;background-color:#B35900;color:white\"> charcter-Level Embedding </div> <div style=\"width:130px;position: absolute;left:418px;color:#E6E600;font-weight: bold;\">-------></div>\n",
    "    \n",
    "<div style=\"width:400px; border:3px solid #CC3333;position: absolute;left:475px;text-align: center;background-color:#CC3333;color:white\">  Secound part </div> <div style=\"width:130px;position: absolute;left:885px;\">  ------->  </div>\n",
    "    \n",
    "</div>\n",
    "<div style=\"height:15%;\"> \n",
    "    \n",
    "<div style=\"width:130px;position: absolute;left:30px;border-left: 6px solid green;height: 20%;margin: 9px;\">  </div> \n",
    "<div style=\"width:80px;position: absolute;left:380px;border-left: 6px solid green;height: 22%;margin: 9px;\">  </div>    \n",
    "\n",
    " </div>\n",
    "<div style=\"height:5%;\"> \n",
    "    \n",
    "<div style=\"width:355px;position: absolute;left:30px;border-top:6px solid green;height: 0px;margin: 9px;\">  </div>    \n",
    "\n",
    "</div>\n",
    "    \n",
    "<div style=\"height:25%;\"> \n",
    "    \n",
    "<div style=\"width:130px;position: absolute;left:200px;border-left: 6px solid green;height:20%;margin: 9px;\">  </div> \n",
    "    \n",
    "\n",
    "</div>\n",
    "    \n",
    "    \n",
    "<div style=\"height:15%;\">\n",
    "    \n",
    "<div style=\"width:170px; border:3px solid #662200;position: absolute;left:9px;text-align: center;background-color:#662200;color:white\"> convolutional layer </div> <div style=\"width:130px;position: absolute;left:186px;\">-------></div>\n",
    "    \n",
    "<div style=\"width:170px; border:3px solid #4D0D00;position: absolute;left:240px;text-align: center;background-color:#4D0D00;color:white\">  max-over-time pooling  </div> <div style=\"width:130px;position: absolute;left:418px;color:#E6E600;font-weight: bold;\">-------></div>\n",
    "    \n",
    "</div>    \n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height:400px;\">\n",
    "<img src=\"https://www.researchgate.net/profile/Miquel_India/publication/319185296/figure/download/fig2/AS:531279130574848@1503678223289/Neural-network-scheme-10.png \" style=\"height:400px;border:3px solid #E6BF00;position: absolute;left:0px\">\n",
    "<img src=\"\" style=\"height:10%;border:3px solid #E6BF00;position: absolute;left:550px\">\n",
    "\n",
    "</div>\n",
    "<div style=\"height:40px;\">\n",
    "<div style=\"height:35px;widht:60px;border:3px solid #E6BF00;position: absolute;left:120px\"><b>FIG1</b></div>\n",
    "<div style=\"height:10%;border:3px solid #E6BF00;position: absolute;left:550px\"></div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:50%;height:40px;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4> Recurrent Neural Network:  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(I described RNN complitly here: <font color=\"blue\">Chapter 009- keras (LSTM tutorial_plus_theory)).ipynb</font> )**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RRN is suited for modeling sequential phenomena. RNN takes the input vector $x_t \\in R_n$ and the hidden state vector $h_{t-1} \\in R_m$ and produces the next hidden state ht by applying the following recursive operation:\n",
    "\n",
    "## $ h_t = f(w.x_t + Uh_{t-1} + b) $   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*AQ52bwW55GsJt6HTxPDuMA.gif\" style=\"wide:100px;border:3px solid black\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A Recurrent Neural Network Language Model (RNN-LM)** specifies a distribution over $w_{t+1}$ (word tokens) by applied affin transformation to hidden layer follwed by a softmax:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $ P(W_{t+1}=i  | W_{1:t}=j) = \\frac{ exp(h_t.p^i+q^i) }{  \\sum_{j \\in N } exp(h_t.p^{j}+q^j) } $ ,(Forward-LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:50%;height:40px;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4> Long short-term memory (LSTM):  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(I described LSTM complitly here: <font color=\"blue\">Chapter 009- keras (LSTM tutorial_plus_theory)).ipynb</font> )**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A LSTM Network is made from four gates have diffretn responsible:\n",
    "\n",
    "1. **cell state,** This gate is responsible for saving memeory of network. cell state goes on its journey, information get’s added or removed to the cell state via gates.\n",
    "2. **Forgat gate,** Forgat gate decides what information is relevant to add from the current step. The output gate determines what the next hidden state should be.\n",
    "3. **input gate,**\n",
    "4. **output gate,** The output gate decides what the next hidden state should be.Remember that the hidden state contains information on previous inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addresses the problem of learning long range dependencies by augmenting the RNN. Concretely, One step of an LSTM takes as input  $x_t, h_{t-1} and c_{t-1}$ and produce $h_t, c_t$ via following intermediate calculations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height:400px;\">\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*yBXV9o5q7L_CvY7quJt3WQ.png\" width=\"500\" style=\"height:400px;border:3px solid #E6BF00;position: absolute;left:0px\">\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTfk5X5Gxz7dGl84frKQ1XtDZiV_k9lljvotJ2P-2xocP0R2K4n\" style=\"border:3px solid #E6BF00;position: absolute;left:500px\">\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here $\\sigma_g(·)$ and $tanh(·)$ are the element-wise sigmoid and hyperbolic tangent functions,<br>\n",
    "$⊙$ is the element-wise multiplication operator, and it, <br>\n",
    "$f_t$, ot are referred to as input, forget, and output gates.<br>\n",
    "At t = 0, $h_0$ and $c_0$ are initialized to zero vectors. <br>\n",
    "\n",
    "**LSTM alleviat gradient vanishing problem of RNN.** Gradient exploding is still an issue, though in practice simple optimization strategies (such as gradient clipping) work well.<bt>\n",
    "    \n",
    "It is easy to extened the RNN or LSTM to more layers by having another netwrok,Indeed, having multiple layers is often crucial for obtaining competitive performance on various tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:50%;height:40px;border: 4px solid black;background-color:#B35900;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4> Character-level Convolutional Neural Network:  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This part is disctibe in **Medium_NLP 004 (CNN in NLP).ipynb** )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input at time t is an output from a character-level convolutional neural network (CharCNN),The character-level convolutional neural network (CharCNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character-level CNN follow steps below:\n",
    "\n",
    "1. $Q ∈ \\mathbb{R}^{d×d}$ be the matrix character embeddings.$d$ be the dimensionality of character embeddings\n",
    "2. $W$ be a Vocabulary that makes  from $l$ dimensional characther Embadding. \n",
    "3. A tagert Word ($W_{k}$) is made up of a sequense of character $[c_1, ... , c_l]$.\n",
    "4. The character-level represention of $W_{k}$, is given by matrix $C^k \\in \\mathbb{R}^{d\\times l}$ (d:number of rows,l:number of columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, when made character-level  Matrix of words, apply a narrow convolution between $C^k$ and a filter (or kernel) $H ∈ \\mathbb{R}^{d×w}$ of width w.\n",
    "Then we add a bias and apply a nonlinearity to obtain a feature map $f^{k} ∈ \\mathbb{R}^{l−w+1}$. the i-th element of fk is given by:\n",
    "\n",
    "## $f^k [i] = tanh(⟨C^k [∗, i : i + w − 1], H⟩ + b)$\n",
    "\n",
    "where $C^k[∗, i : i+w−1]$ is the $i-to-(i+w−1)-th$ column of $C^k$ and $<A, B> = Tr(AB^T )$ is the Frobenius inner product. Finally, we take the max-over-time:\n",
    "\n",
    "## $y^k = max f^k[i]$\n",
    "\n",
    "The idea is to capture the most important feature— the one with the highest value—for a given filter. A filter is essentially picking out a character n-gram, where the size of the n-gram corresponds to the filter width. Our CharCNN uses multiple filters of varying widths to obtain the feature vector for k (tagert-word).<br>\n",
    "So if we have **a total of h filters $H_1,...,H_h$**, then $y^k = [y_1^k , . . . , y_h^k ]$ is the input representation of k (tagert). For many NLP applications h is typically chosen to be in [100, 1000]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:50%;height:40px;border: 4px solid black;background-color:#006611;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4>  1Highway Network: </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"B\" style=\"width:100%;height:70px;border: 4px solid black;background-color:#B35900;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h3>  Character-level Convolutional Networks for Text Classification </h3>\n",
    "    <h5> 2016, Xiang Zhang</h5>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #4D0033;background-color:#00404D;color:black;border-radius: 5px;padding:7px;color:white;\">\n",
    "  <strong> Summary: </strong><br>\n",
    "- This article offers an empirical study on character-level convolutional networks for text classifica- tion.         \n",
    "- This paper explore treating text as kind of raw signal at character level, and applying temporal (one-dimensional) ConvNets to it.  also build several of large datasets to work. An extensive set of comparisons is offered with traditional models and other deep learning models.         \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #B35900;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "    \n",
    "(1) https://arxiv.org/pdf/1509.01626.pdf\n",
    "    \n",
    "(2) https://www.youtube.com/watch?v=CNY8VjJt-iQ\n",
    "\n",
    "(3A) code: http://mxnet.incubator.apache.org\n",
    "\n",
    "(3B) code: https://github.com/ThomasDelteil/TextClassificationCNNs_MXNet/blob/master/Crepe-Gluon.ipynb\n",
    "\n",
    "(3C) code: https://github.com/ThomasDelteil/TextClassificationCNNs_MXNet\n",
    " \n",
    "(4) /Users/apple/Documents/Farhad-DC/iPaper/**Character-level Convolutional Networks.pdf**\n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "1. Deep ConvNets don't require the knowlage of words, \n",
    "2. Deep ConvNets don't require the knowlage  about the syntactic or semantic structure of a language. \n",
    "3.  Working on only characters also has the advantage that abnormal character combinations such as misspellings and emoticons may be naturally learnt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:50%;height:40px;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4>  1-D convolution: </h4>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have $g(x)$ as a input matrix (or funcation) and and we also have  a discrete kernel Matrix (or funcation) $Ke(x)$.<br>\n",
    "The convolution $h(y)$ between $g(x)$ and $ke(x)$ with stride d is defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $ h(x,y) = (ke * f)(x,y) = \\displaystyle\\sum_{s=0}^{k-1} \\sum_{t=0}^{v-1} ke(s,t).g(x-s,y-t)  $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If: <br>\n",
    "$g(x)   \\in [v,l] -> \\mathbb{R} $,<br>\n",
    "$ke(x)  \\in [1,k] -> \\mathbb{R} $,<br>\n",
    "$h(x)   \\in [1,[(l-k)/d]+1] -> \\mathbb{R} $,<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding temporal **Max-Pooling** to notwork helps us to train deeper models.\n",
    "\n",
    "The algorithm used is stochastic gradient descent (SGD) with a minibatch of size 128. using momentum 0.9 and initial step size 0.01 which is halved every 3 epoches for 10 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:<br>\n",
    "\n",
    "<div style=\"height:130px;border:3px solid #661100;padding:12px\">\n",
    "<div style=\"position:absolute\">\n",
    "$G_{matrix}=\\begin{pmatrix}\n",
    "A_{11} & B_{12} & C_{13} \\\\\n",
    "A_{21} & B_{22} & C_{23} \\\\\n",
    "A_{31} & B_{32} & C_{33}\\\\\n",
    "\\vdots  & \\vdots & \\vdots \\\\\n",
    "A_{l1} & B_{l2} & C_{l3}\\\\\n",
    " \\end{pmatrix}$\n",
    "</div> <div style=\"position:absolute;left: 17%;top:50%;color:green;font-weight: bold;\"> and </div>\n",
    "<div style=\"position:absolute;left: 20%;top:39%\"> \n",
    "\n",
    "$ke_{kernel}= \\begin{pmatrix}   \n",
    "K_{11} & K_{12} \\\\\n",
    "K_{11} & K_{12} \\\\\n",
    "\\vdots  & \\vdots \\\\\n",
    "\\end{pmatrix}$  \n",
    "</div><div style=\"position:absolute;left: 35%;top:50%;color:green;font-weight: bold;\"> give a new matrix H : </div>\n",
    "    \n",
    "<div style=\"position:absolute;left: 49%;top:50%\">  \n",
    "$ H = \\begin{pmatrix}   \n",
    "h_{1} & h_{2} \n",
    "\\end{pmatrix}$  \n",
    "</div>  <div style=\"position:absolute;left: 59%;top:50%;color:green;font-weight: bold;\"> That is equal: </div>  \n",
    "<div style=\"position:absolute;left: 69%;top:27%\">      \n",
    "$H = \\begin{pmatrix}   \n",
    "h_{1} = \\displaystyle\\sum_{j}^{l} K_{11}.A_{j1} + \\sum_{j}^{l} K_{12}.B_{j2}    \\\\\n",
    "h_{2} = \\displaystyle\\sum_{j}^{l} K_{12}.B_{j2} + \\sum_{j}^{l} K_{13}.C_{j3} \\\\\n",
    "\\end{pmatrix}$  \n",
    "\n",
    "</div>     \n",
    "</div>     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:50%;height:40px;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4> Character quantization:  </h4>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They used a charcter one-hot vector for every alphabet that is used in context. The alphabet used in all of their **models consists of 70 characters**, including **26 english letters**, **10 digits**, **33 other characters and the new line character**. The non-space characters are:\n",
    "\n",
    "\n",
    "- 26 english letters: **abcdefghijklmnopqrstuvwxyz**\n",
    "- 10 digits:  **0123456789** \n",
    "-  33 other characters and the new line character:  **, ; . ! ? : ’’’/\\|_@#$%ˆ&* ̃‘+-=<>()[]{}**\n",
    "\n",
    "They also **distinguish between upper-case and lower-case letters** in their model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:50%;height:40px;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4> Model Design:  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Model is **designed 2 ConvNets – one large and one small**. 2 ConvNets is made by **9 layers deep with 6 convolutional layers and 3 fully-connected layers** and also inserted **2 dropout modules** in between the 3 fully-connected layers to regularize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data:image/png;base64,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\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input have number of features equal to 70 due to our character quantization method, and the input feature length is 1014."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:50%;height:40px;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4> Comparison Models:  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "traditional methods as those that using a hand-crafted feature extractor and a linear classifier:\n",
    "\n",
    "### Bag-of-words and its TFIDF:\n",
    "the bag-of-words model is constructed by selecting 50,000 most frequent words from the training subset.\n",
    "\n",
    "### Bag-of-ngrams and its TFIDF:\n",
    " The bag-of-ngrams models are constructed by selecting the 500,000 most frequent n-grams (up to 5-grams) from the training subset for each dataset.\n",
    " \n",
    "### Bag-of-means on word embedding:\n",
    "an experimental model that uses k-means on word2vec learnt from the training subset of each dataset, and then use these learnt means as representatives of the clustered words. The dimension of the embedding is 300.  The number of means is 5000.\n",
    "\n",
    "### Word-based ConvNets:\n",
    "Among the large number of recent works on word-based ConvNets for text classification, one of the differences is the choice of using pretrained or end-to-end learned word representations.(like word2vec  and glove)\n",
    "\n",
    "### Long-short term memory:\n",
    "a comparison with a recurrent neural network model, namely long-short-term memory (LSTM).The LSTM model used in our case is word-based, using pretrained word2vec embedding of size 300 as in previous models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** \n",
    "- distinguish between upper-case and lower-case letters usually (but not always) gives worse results.\n",
    "- They choose 5 categories – “sports”, “finance”, “entertainment”, “automobile” and “technology”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:50%;height:40px;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4> Dataset that they used:  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **AG’s news corpus**, AG’s corpus of news article on the web2.It contains 496,835 categorized news articles from more than 2000 news sources.\n",
    "- **Sogou news corpus**, a combination of the SogouCA and SogouCS news corpora, containing in total 2,909,551 news articles in various topic channels\n",
    "- **DBPedia ontology dataset**, DBpedia is information from Wikipedia\n",
    "- <font color=\"red\">**Yelp reviews**, he Yelp reviews dataset is obtained from the Yelp Dataset Challenge in 2015. This dataset contains 1,569,264 samples that have review texts.Two classification tasks are constructed from this dataset – one predicting full number of stars the user has given and the other predict- ing a polarity label by considering stars 1 and 2 negative, and 3 and 4 positive </font>\n",
    "- **Yahoo! Answers dataset**, Answers Comprehensive Questions and Answers version 1.0 dataset through the Yahoo! Webscope program.\n",
    "- **Amazon reviews**,  an Amazon review dataset from the Stanford Network Analysis Project (SNAP), which spans 18 years with 34,686,770 reviews from 6,643,669 users on 2,441,053 products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:50%;height:40px;border: 4px solid black;background-color:#009999;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4> Conclusion:  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The most important conclusion from our experi- ments is that character-level ConvNets could work for text classification without the need for words.\n",
    "- Amazon reviews tend to be raw user-inputs, whereas users might be extra careful in their writings on Yahoo! Answers. Plots comparing word-based deep models (figures 3c, 3d and 3e) show that character-level ConvNets work better for less curated user-generated texts. This property suggests that ConvNets may have better applicability to real-world scenarios.\n",
    "- Our datasets consist of two kinds of tasks: sentiment analysis (Yelp and Amazon reviews) and topic classification (all others). This dichotomy in task semantics does not seem to play a role in deciding which method is better.\n",
    "-  the bag-of-means model performs worse in every case.\n",
    "\n",
    "- They gratefully acknowledge the support of NVIDIA Corporation with the donation of 2 Tesla K40 GPUs used for this research. They gratefully acknowledge the support of Amazon.com Inc for an AWS in Education Research grant used for this research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
