{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:100px;text-align:center;border: 4px solid black;background-color:#E6BF00;color:white\">\n",
    "\n",
    "<header style=\"width:100%;height:100px;\">\n",
    "  <h1><b> Session 008</b></h1>\n",
    "    <h4> Basic Natural language processing </h4>\n",
    "</header>\n",
    "\n",
    "<div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='border: 4px solid #E6BF00;padding:9px;'>\n",
    "\n",
    "By: Farhad Shadmand \n",
    "    \n",
    "https://github.com/farhadsh1992\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height:60px\">\n",
    "<img src=\"https://i0.wp.com/mlexplained.com/wp-content/uploads/2019/01/allennlp-logo-dark.png?fit=1200%2C211\" style=\"height:60px;position:absolute;left:30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #3550B7;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "\n",
    "paper: https://aclweb.org/anthology/N18-1202\n",
    "    \n",
    "Elmo: https://allennlp.org/elmo\n",
    "    \n",
    "paper: https://www.aclweb.org/anthology/N18-1202\n",
    "    \n",
    "github: https://github.com/allenai/bilm-tf\n",
    "\n",
    "(ULMFIT): universal language model fine-tuning for text classfication\n",
    "\n",
    "paper: https://arxiv.org/abs/1801.06146\n",
    "    \n",
    "github: https://github.com/akzaidi/fine-lm\n",
    "    \n",
    "https://www.youtube.com/watch?v=DXdJlY35eVE&list=PL3EpmjYtZedx30x6JtcLyoxqJ89eNstMx&index=41&t=6s\n",
    "    \n",
    "pytorch-fast-elmo: https://pypi.org/project/pytorch-fast-elmo/\n",
    "    \n",
    "https://www.youtube.com/watch?v=ddf0lgPCoSo\n",
    "    \n",
    "AllenNLP: https://github.com/allenai/bilm-tf\n",
    "\n",
    "https://allennlp.org/elmo\n",
    "    \n",
    "more paper: https://datawarrior.wordpress.com/2018/07/12/embedded-language-models/\n",
    "    \n",
    "http://www.davidsbatista.net/blog/2018/12/06/Word_Embeddings/\n",
    "    \n",
    "    \n",
    "RNN: http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "    \n",
    "https://vimeo.com/277672840\n",
    "    \n",
    "<hr>\n",
    "\n",
    "review word embedding approch: https://towardsdatascience.com/beyond-word-embeddings-part-2-word-vectors-nlp-modeling-from-bow-to-bert-4ebd4711d0ec\n",
    "    \n",
    "https://medium.com/cityai/deep-learning-for-natural-language-processing-part-iii-96cfc6acfcc3\n",
    "    \n",
    "\n",
    "    \n",
    "<hr>    \n",
    "    \n",
    "project in nlp: https://towardsdatascience.com/beyond-word-embeddings-part-1-an-overview-of-neural-nlp-milestones-82b97a47977f\n",
    "    \n",
    "https://medium.com/jatana/report-on-text-classification-using-cnn-rnn-han-f0e887214d5f\n",
    "    \n",
    "Text Summarization: https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1?source=placement_card_footer_grid---------0-4\n",
    "    \n",
    "https://www.youtube.com/watch?v=zKSt3afh8Cw\n",
    "    \n",
    "https://www.youtube.com/watch?v=9let-7SCKA4\n",
    "    \n",
    "https://www.youtube.com/watch?v=-UaTdVGfHxQ\n",
    "    \n",
    "translation paper: https://arxiv.org/pdf/1708.00107.pdf\n",
    "    \n",
    "    \n",
    "translation githup: https://github.com/salesforce/cove\n",
    "    \n",
    "tensor2tensor; https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/data_generators/wikisum\n",
    "\n",
    "Bert paper: https://arxiv.org/abs/1810.04805\n",
    "    \n",
    "descripe BERT paper: https://www.youtube.com/watch?v=ah7_mfl7LD0\n",
    "\n",
    "https://github.com/google-research/bert\n",
    "    \n",
    "Self_attenation: https://www.youtube.com/watch?v=OYygPG4d9H0\n",
    "<hr> \n",
    "    \n",
    "BiLSTM: https://towardsdatascience.com/understanding-bidirectional-rnn-in-pytorch-5bd25a5dd66\n",
    "    \n",
    "BiRNN: https://medium.com/@plusepsilon/the-bidirectional-language-model-1f3961d1fb27\n",
    "    \n",
    "unidirectional language model: https://medium.com/jim-fleming/implementing-lstm-a-search-space-odyssey-7d50c3bacf93\n",
    "    \n",
    "paper (Contextual Bidirectional LSTM): https://www.aclweb.org/anthology/E17-1096\n",
    "    \n",
    "paper: https://openreview.net/pdf?id=BydLzGb0Z\n",
    "    \n",
    "paper (tagging with bidirectional language models): https://arxiv.org/abs/1705.00108\n",
    "    \n",
    "paper (Training Bi-directional Neural Network Language): https://arxiv.org/pdf/1602.06064.pdf\n",
    "    \n",
    "<hr>\n",
    "\n",
    "important: https://towardsdatascience.com/spam-filtering-system-with-deep-learning-b8070b28f9e0\n",
    "    \n",
    "important: https://towardsdatascience.com/time-series-forecasting-with-deep-stacked-unidirectional-and-bidirectional-lstms-de7c099bd918\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:70px;border: 4px solid black;background-color:#E6BF00;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h1> Embedding from Language Model (ELMo) <h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:25%;height:40px;border: 4px solid black;background-color:#E6BF00;color:white;text-align:center;border-radius:0px 25px 25px 0px;padding:3px\">\n",
    "    <h4> contents:  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:#E6BF00;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#1\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> Theory </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#2\" style=\"position: relative;padding:5px;color:white;text-align: center;\">  Bidirectional language models: </a></h6>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#3\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> context-independent token representation </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#4\" style=\"position: relative;padding:5px;color:white;text-align: center;\">  What is ELMo? </a></h6>\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#5\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> ELMo Architecture</a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:#0026E6;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#6\" style=\"position: relative;padding:5px;color:white;text-align: center;\">  Embedding layer </a></h6>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:#B35900;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#7\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> Trensformas Character embeddings: </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:#8800CC;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#8\" style=\"position: relative;padding:5px;color:white;text-align: center;\">  Convolutional Neural Network: </a></h6>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:#006611;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#9\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> The highway Network Layers: </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:white;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#10\" style=\"position: relative;padding:5px;color:white;text-align: center;\">  </a></h6>\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:#E6BF00;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#11\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> Python Code for  ELMo </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#12\" style=\"position: relative;padding:5px;color:white;text-align: center;\">  ELMo 0 to 100 </a></h6>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#13\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> Use TF-hub of google for elmo: ¶ </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:#E6BF00;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#14\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> ELMo , plus-code  </a></h6>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#15\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> my pakage for Elmo (Elmo_Thrones):  </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#16\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> simple data:   </a></h6>\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align:center;height:45px\">\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:0 ;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#17\" style=\"position: relative;padding:5px;color:white;text-align: center;\"> my really data:  </a></h6>\n",
    "</div>\n",
    "<div style=\"width:49%;height:30px;position:absolute;left:50% ;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius:25px 25px 25px 25px;padding:3px\">\n",
    "    <h6><a href=\"#18\" style=\"position: relative;padding:5px;color:white;text-align: center;\">  </a></h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"1\" style=\"width:100%;height:70px;border: 4px solid black;background-color:#E6BF00;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h1> Theory <h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #3550B7;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "\n",
    "(1) paper: [Deep contextualized word representations](https://aclweb.org/anthology/N18-1202)\n",
    "    Matthew E. Peters†, Mark Neumann†, Mohit Iyyer†, Matt Gardner†, Christopher Clark∗, Kenton Lee∗, Luke Zettlemoyer†\n",
    "    \n",
    "    \n",
    "(2) [Howard, Jeremy, and Sebastian Ruder. \"Universal language model fine-tuning for text classification.\" arXiv preprint arXiv:1801.06146 (2018).](https://arxiv.org/abs/1801.06146)\n",
    "    \n",
    "(3) https://towardsdatascience.com/understanding-bidirectional-rnn-in-pytorch-5bd25a5dd66\n",
    "    \n",
    "(4) BiRNN: https://medium.com/@plusepsilon/the-bidirectional-language-model-1f3961d1fb27\n",
    "    \n",
    "(5)https://vimeo.com/277672840\n",
    "    \n",
    "(6) video of paper1: https://www.youtube.com/watch?v=9JfGxKkmBc0\n",
    "    \n",
    "slide: https://aisc.a-i.science/static/slides/20180604_ChrisLaver.pdf\n",
    "    \n",
    "(7) https://www.mihaileric.com/posts/deep-contextualized-word-representations-elmo/\n",
    "    \n",
    "(8) paper: [Character-Aware Neural Language Models](https://arxiv.org/pdf/1508.06615.pdf)\n",
    "    \n",
    "(9) https://www.mihaileric.com/posts/deep-contextualized-word-representations-elmo/\n",
    "    \n",
    "(10) paper: [Highway Networks](https://arxiv.org/pdf/1505.00387.pdf)\n",
    "    \n",
    "(11) https://en.wikipedia.org/wiki/Highway_network\n",
    "   \n",
    "    \n",
    " </div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:40px;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> Abstract  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This has been developed by the Allen Institute for Artificial Intelligence.**\n",
    "\n",
    "ELMo is Langauage Models (LMS).\n",
    "<hr>\n",
    "\n",
    "<font color=\"red\">The Embeddings from Language Models (ELMo)</font> can be **divided into two main tasks**, first we train **an LSTM-based language model** on some corpus, and then we use the **hidden states of the LSTM for each token to generate a vector representation** of each word.\n",
    "\n",
    "<hr>\n",
    "Learning high quality representation can be challenging, They should ideally model both:\n",
    "1. Complex characteristic of word use (syntax and semantics),\n",
    "2. How these uses vary across linguistic contexts . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Model is designed from part below:\n",
    "1. \n",
    "2.\n",
    "3. X, context-independent token representation. \n",
    "4. Bidirectional language models.\n",
    "5. Add all results of ever Bidirectional layer eachother and alos with input of Bidirectional.(**compute a task specific weighting of all biLM layers**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"2\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> Bidirectional language models:  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An RNN (theoretically) gives us infinite left context (words to the left of the target word). But what we would really like is to use both left and right contexts by **bidirectional language model** , **[REF4]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*HNF-Klzkex58xRkxWvI0dw.png\" style=\"width:300px\"> **FIG1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ususally use two  sets of RNN hidden vectors where one is the output of forword RNN and the other is the output of the backward RNN. These will be used to predict the next word in the sentence, where next word is the previous word for the backward RNN.<br>\n",
    "(Note: the scientist usually  use a BOS (for beginning of sentence)and a EOS (for end of sentence) padding tokens.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*PB5HXSXOGJrnDa_Si4nj9Q.png\" style=\"width:400px; position: absolute;left:0px\">\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*6QnPUSv_t9BY9Fv8_aLb-Q.png\" style=\"width:600px;position:static;left:0px;\">\n",
    "\n",
    "**FIG2**                                            <space>                           **FIG3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is similar to word2vec,  with this contract that bidirectional language models has infinite context from the RNN.[REF4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider we have a  tokization words $(w_1, w_2, ... , w_N)$, a forward langauage model compute the probablility of sequence by modeling of the probablity of token target $w_{target}$ given the history $(w_1, ... , w_{target})$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $  p(w_1, w_2, ... , w_N ) = \\displaystyle\\prod_{target=1}^{N} p(w_{target}| w_1, w_2, ... , w_{target}) $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then pass through  $L$ layers of **forward** LSTM (FIG2). At each position $target$, each sentation output is $ \\overrightarrow{outF}_{target,j}$ ,  where $j= 1 , ... , L$ The top (last )layer LSTM output, $ \\overrightarrow{outF}_{target,L}$ , is used to predict next token $w_{target+1}$ with **softmax** layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**backwards biLSTM** is similar to a forward forwards,  except it runs over the sequence in reverse, predict- ing the previous token given the future context:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $  p(w_1, w_2, ... , w_N ) = \\displaystyle\\prod_{target=1}^{N} p(w_{target}| w_{target+1}, w_{target+2}, ... , w_{N}) $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be implemented in an analogous way to a forward biLSTM, with each backward biLSTM layer $j$ in a $L$ layer deep model producing representations  of tk given $ \\overleftarrow{outB}_{target,j} $ of $w_{target}$ given, $(t_{target+1},t_{target+2},...,t_{N})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A biLM combines both a forward and backward**. formulation jointly maximizes the log likelihood of the forward and backward directions (one by one, **FIG3**):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ H_{target} = \\displaystyle\\sum_{target}^{N} (log p(w_{target}|w_1, w_2, ... , w_{target-1} ) + log p(w_{target}|p(w_{target+1},p(w_{target+2}, ... , p(w_{N} )) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with consider to  tie the parameters for **both the token representation and Softmax layer** n the forward and backward direction.**[REF1]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"3\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> context-independent token representation $X_{target}$: :  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In very short description, X is first word-embedding input layers that gives to Biderctional for addtional embedding and alos add to other layer in last part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Supervisered NLP models share a common archticture at the lowest layers, allowing us to ElMo in a constant, unified manner. given  a sequenses of tokens $ (w_{1}, w_{2}, ... , w_{N}) $, it is standard to form a context-independent token representation $x_{target}$ for each token postion using pre-training wprd embedding and optionally character-based representations.\n",
    "\n",
    "**$X_{target}$ is  a context-independent token representation that is computed via token embeddding or a CNN over characters) ([Jo ́zefowicz et al., 2016](https://arxiv.org/pdf/1602.02410.pdf); [Melis et al., 2017; Mer-ity et al., 2017](https://arxiv.org/pdf/1707.05589.pdf),])**  then pass it through L layers of forward LSTMs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"4\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> What is ELMo?  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELMo is **a linear combination of the many biLSTM layers** for learning word representation.**[REF1]**   <br>\n",
    "Each word token $W_{target}$, a $L-layer$ biLSTM compute a set of $2L+1$ representation,\n",
    "\n",
    "### $Rep_{target} = [ X_{target} ,outF_{target,j}, outB_{target,j}| j=1,..., L ] $\n",
    "\n",
    "### $Rep_{target} = [ h_{target,j}| j= 0,..., L ]$\n",
    "\n",
    "where $h_{target,0}$ is the token layer, <br>\n",
    "**$X_{target}$ is  a context-independent token representation that is computed via token embeddding or a CNN over characters) ([Jo ́zefowicz et al., 2016](https://arxiv.org/pdf/1602.02410.pdf); [Melis et al., 2017; Mer-ity et al., 2017](https://arxiv.org/pdf/1707.05589.pdf),])**  then pass it through L layers of forward LSTMs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**In the simplest ELMo case**, ELMo just selects the top layer, $ E(Rep_{target}) = h_{target, L} $ <br>\n",
    "(as in TagLM (Peters et al., 2017) and CoVe (Mc- Cann et al., 2017). )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More generally, **compute a task specific weighting of all biLM layers:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $ ELMo_{target}^{Task} = E(Rep_{target}; FUN^{Task} ) $\n",
    "\n",
    "\n",
    "<font size=\"8px\" color=\"#801500\"> $ ELMo_{target}^{Task} = \\gamma^{task} \\displaystyle\\sum_{j=0}^{L} S_{j}^{Task} h_{}^{target,j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ S^{Task}_{j} $ are softmax-normalized wieghts and the scalar parmter $\\gamma^{task}$   allows the task model to scale the entire ELMo vector.  <br>\n",
    "$\\gamma^{task}$ is of practical importance to aid the optimization process.\n",
    "\n",
    "**In some cases it also helped to apply layer normalization [(Ba et al., 2016)](https://arxiv.org/pdf/1607.06450.pdf) to each biLM\n",
    "layer before weighting.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*euk-3hzyi9nJvTdWFmfrqQ.png\" style=\"border:3px solid #E6BF00\"> <br>\n",
    "**FIG4**(input layer + TWo Bi-directional LSTM layers + output layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Note:**\n",
    "The basic case, when $\\gamma^{task}=1$ and $ S^{Task}_{L}=1 $ , is equivalent to **the vanilla langauge model** presented eariler.<br>\n",
    "The general case, we choose a set of $\\gamma^{task}$ and $ S^{Task}$. we freeze the parameters of the langauge model used to genrate $R_{target}$, then train $\\gamma^{task}$ and $ S^{Task}$ as parmarters of the task-spesific model in which we are including $ELMo^{tsak}$. **[REF6,7]** \n",
    "\n",
    "the ELMo language model is trained on a sizable dataset: the 1B Word Benchmark. In addition, the language model really is large-scale with the LSTM layers containing 4096 units and the input embedding transform using 2048 convolutional filters. **[REF9]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"5\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> ELMo Architecture     </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #3550B7;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "\n",
    "https://www.mihaileric.com/posts/deep-contextualized-word-representations-elmo/\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from a Standard langauge model achitecture,**[REF6,7]** :\n",
    "\n",
    "1. use multiple layers of recurrent units in th encoder,\n",
    "2. Keep all the intenal layer representions, in addition to the final recurrent layer,\n",
    "3. For any downstream task, create the task-specific embedding as a linear combination of all the internal layer representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:3px solid #E6BF00;padding:20px;\">\n",
    "<div style=\"height:20px;\">\n",
    "<div style=\"width:130px; border:3px solid #0026E6;position: absolute;left:9px;text-align: center;background-color:#0026E6;color:white\"> embedding_layer </div> <div style=\"width:130px;position: absolute;left:148px;\">-------></div>\n",
    "<div style=\"width:80px; border:3px solid #AB274F;position: absolute;left:205px;text-align: center;background-color:#AB274F;color:white\"> $biLM_1$ </div> <div style=\"width:130px;position: absolute;left:295px;\">-----></div>\n",
    "<div style=\"width:80px; border:3px solid #AB274F;position: absolute;left:345px;text-align: center;background-color:#AB274F;color:white\"> $biLM_2$ </div> <div style=\"width:140px;position: absolute;left:440px;\">------></div>\n",
    "    \n",
    "<div style=\"width:80px; border:3px solid #AB274F;position: absolute;left:490px;text-align: center;background-color:#AB274F;color:white\"> ... </div> <div style=\"width:130px;position: absolute;left:580px;\">------></div>\n",
    "    \n",
    "<div style=\"width:80px; border:3px solid #AB274F;position: absolute;left:630px;text-align: center;background-color:#AB274F;color:white\"> $biLM_L$ </div> <div style=\"width:130px;position: absolute;left:720px;color:green;\">-----></div>    \n",
    "<div style=\"width:60px; border:3px solid green;position: absolute;left:750px;text-align: center;background-color:green;color:white\"> $\\bigotimes S^{task}_{L}$  </div> \n",
    "<div style=\"width:130px;position: absolute;left:810px;color:green\">-----></div>        \n",
    "<div style=\"width:150px; border:3px solid #EFDECD;position: absolute;left:860px;text-align: center;background-color:#EFDECD\">  Dense(Linear) </div> <div style=\"width:130px;position: absolute;left:1020px;color:green\">-----></div>\n",
    "    \n",
    "<div style=\"width:170px; border:3px solid #00BFE6;position: absolute;left:1070px;text-align: center;background-color:#00BFE6\">  $\\bigotimes \\gamma (task)$ </div> \n",
    "\n",
    "</div>  \n",
    "\n",
    "<div style=\"height:30px;\" id=\"secound_layer\">\n",
    "    \n",
    "<div style=\"width:130px;position: absolute;left:65px;border-left: 6px solid green;height: 40px;margin: 9px;\"> &darr;  </div> \n",
    "<div style=\"width:80px;position: absolute;left:245px;border-left: 6px solid green;height: 40px;margin: 9px;\"> &darr; </div> \n",
    "<div style=\"width:80px;position: absolute;left:385px;border-left: 6px solid green;height: 35px;margin: 9px;\"> &darr; </div>     \n",
    "<div style=\"width:80px;position: absolute;left:520px;border-left: 6px solid green;height: 35px;margin: 9px;\"> &darr; </div> \n",
    "    \n",
    "\n",
    "<div style=\"width:200px; position: absolute;left:880px;border-left: 6px solid green;height: 36px;margin: 9px;\"> &uarr; </div>\n",
    "<div style=\"width:200px; position: absolute;left:900px;border-left: 6px solid green;height: 45px;margin: 9px;\"> &uarr; </div>\n",
    "    \n",
    "<div style=\"width:200px; position: absolute;left:920px;border-left: 6px solid green;height: 45px;margin: 9px;\"> &uarr; </div>\n",
    "\n",
    "<div style=\"width:200px; position: absolute;left:940px;border-left: 6px solid green;height: 35px;margin: 9px;\"> &uarr; </div>\n",
    "<div style=\"width:200px; position: absolute;left:1145px;border-left: 6px solid green;height: 24px;margin: 9px;\">  &darr;  </div>\n",
    "\n",
    "    \n",
    "</div>\n",
    "\n",
    "<div style=\"height:30px;\" id=\"third_layer\">\n",
    "    \n",
    "<div style=\"width:130px;position: absolute;left:65px;border-left: 6px solid green;height: 40px;margin: 9px;\">  </div> \n",
    "<div style=\"width:80px;position: absolute;left:245px;border-left: 6px solid green;height: 45px;margin: 9px;\">  </div> \n",
    "<div style=\"width:80px;position: absolute;left:385px;border-left: 6px solid green;height: 35px;margin: 9px;\">  </div>\n",
    "    \n",
    "<div style=\"width:200px; position: absolute;left:900px;border-left: 6px solid green;height: 35px;margin: 9px;\"> </div> \n",
    "    \n",
    "<div style=\"width:200px; position: absolute;left:920px;border-left: 6px solid green;height: 35px;margin: 9px;\"> </div>\n",
    "<div style=\"width:200px; position: absolute;left:940px;border-left: 6px solid green;height: 35px;margin: 9px;\"> </div>\n",
    "    \n",
    "<div style=\"width:366px;position: absolute;left:520px;border-top:6px solid green;height: 40px;margin: 9px;\">  </div> \n",
    "<div style=\"width:60px; border:3px solid green;position: absolute;left:650px;text-align: center;background-color:green;color:white\"> $\\bigotimes S^{task}_{...}$  </div>     \n",
    "    \n",
    "<div style=\"width:170px; border:3px solid black;position: absolute;left:1070px;text-align: center;\"> $ELMo_{target}$ </div> \n",
    "  \n",
    "     \n",
    "</div>\n",
    "\n",
    "<div style=\"height:30px;\" id=\"forth_layer\" >\n",
    "    \n",
    "<div style=\"width:130px;position: absolute;left:65px;border-left: 6px solid green;height: 40px;margin: 9px;\">  </div>\n",
    "<div style=\"width:80px;position: absolute;left:245px;border-left: 6px solid green;height: 35px;margin: 9px;\">  </div>\n",
    "    \n",
    "<div style=\"width:200px; position: absolute;left:920px;border-left: 6px solid green;height: 35px;margin: 9px;\"> </div>\n",
    "<div style=\"width:200px; position: absolute;left:940px;border-left: 6px solid green;height: 45px;margin: 9px;\"> </div>    \n",
    "\n",
    "<div style=\"width:520px;position: absolute;left:385px;border-top:6px solid green;height: 40px;margin: 9px;\">  </div> \n",
    "<div style=\"width:60px; border:3px solid green;position: absolute;left:650px;text-align: center;background-color:green;color:white\"> $\\bigotimes S^{task}_{2}$  </div>        \n",
    "    \n",
    "</div>\n",
    "\n",
    "<div style=\"height:30px;\"id=\"fiveth_layer\" >\n",
    "    \n",
    "<div style=\"width:130px;position: absolute;left:65px;border-left: 6px solid green;height: 35px;margin: 9px;\">  </div> \n",
    "<div style=\"width:200px; position: absolute;left:940px;border-left: 6px solid green;height: 35px;margin: 9px;\"> </div>\n",
    "    \n",
    "<div style=\"width:675px;position: absolute;left:245px;border-top:6px solid green;height: 400px;margin: 9px;\">  </div> \n",
    "<div style=\"width:60px; border:3px solid green;position: absolute;left:650px;text-align: center;background-color:green;color:white\"> $\\bigotimes S^{task}_{1}$  </div>\n",
    "\n",
    " \n",
    "</div>\n",
    "\n",
    "<div style=\"height:30px;\" id=\"sixth_layer\">    \n",
    "<div style=\"width:880px;position: absolute;left:65px;border-top:6px solid green;height: 400px;margin: 9px;\">  </div> \n",
    "<div style=\"width:60px; border:3px solid green;position: absolute;left:650px;text-align: center;background-color:green;color:white\"> $\\bigotimes S^{task}_{0}$  </div>    \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height:400px;\">\n",
    "<img src=\"https://petrlorenc.github.io/images/elmo/youtube.png \" style=\"width:550px;height:400px;border:3px solid #E6BF00;position: absolute;left:0px\">\n",
    "<img src=\"https://irenelizihui.files.wordpress.com/2018/12/elmo1.png\" style=\"width:650px;height:400px;border:3px solid #E6BF00;position: absolute;left:550px\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height:300px;\">\n",
    "<img src=\"https://www.mihaileric.com/static/biLM_with_residual-096e1ae8acc0d3f846f0a71da2be3449-300e1.png\" style=\"width:346px;border:3px solid #E6BF00;position: absolute;left:0px\">\n",
    "<img src=\"https://www.mihaileric.com/static/elmo_combination-a7af2b3eb2b5ceb37f3e9c5f2b066f14-4b2d3.png\" style=\"width:550px;border:3px solid #E6BF00;position:absolute;left:355px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"6\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#0026E6;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> Embadding layer:  </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of option for first layer like bag_of_words, Glove or FastText or a simple Embadding layer (asmatrix of size (Vocabulary size) x (Word embedding dimension)).<br> \n",
    "Insted of words, we also can used charcters and pass them through a Convolutional Neural Network as Embadding layer,  see gifure below. \n",
    "This model from three part:\n",
    "1. character embeddings,\n",
    "2. convolution Neural Network (convolutional-layer + Max-pooling) **[REF8]**\n",
    "3. 2-layer Highway Network. **[REF11]**\n",
    "\n",
    "4.  then forms the core of the next aprt of ELMo language model (L biLM layers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:20%;border:5px solid #0026E6;padding:3px;text-align: center;background-color:#0026E6;color:white\">\n",
    " Embedding part of Elmo by a NN:   \n",
    "</div>\n",
    "<div style=\"border:5px solid #0026E6;padding:3%;width:940px\">\n",
    "<div style=\"height:20px;\">\n",
    "    \n",
    "<div style=\"width:200px; border:3px solid #B35900;position: absolute;left:12px;text-align: center;background-color:#B35900;color:white\"> 1. Character Embeddings </div> <div style=\"width:130px;position: absolute;left:218px;\">-------></div>\n",
    "<div style=\"width:200px; border:3px solid #8800CC;position: absolute;left:275px;text-align: center;background-color:#8800CC;color:white\"> 2. Convolutional Layer  </div> <div style=\"width:130px;position: absolute;left:485px;\">-------></div>\n",
    "    \n",
    "<div style=\"width:200px; border:3px solid #8800CC;position: absolute;left:540px;text-align: center;background-color:#8800CC;color:white\"> 2. Max-Pooling </div> <div style=\"width:140px;position: absolute;left:746px;\">------></div>\n",
    "    \n",
    "<div style=\"width:200px; border:3px solid #006611;position: absolute;left:800px;text-align: center;background-color:#006611;color:white\"> 3. two-layer Highway Network </div> <div style=\"width:130px;position: absolute;left:1010px;\">------></div>\n",
    "    \n",
    "<div style=\"width:200px; border:3px solid #AB274F;position: absolute;left:1060px;text-align: center;background-color:#AB274F;color:white\"> 4. Ready for BiLM-part </div> <div style=\"width:130px;position: absolute;left:2720px;color:green\">-----></div>    \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First,  convert each token to an appropriate representation using character embeddings (for example: a embedding keras layer,or glove), hen run through a convolutional layer using some number of filters, followed by a max-pool layer Finally this representation is passed through a 2-layer highway network **[REF9]** .<br> \n",
    "\n",
    "This **trensformas character embeddings** to the inputs token_words have a number of advantages:**[REF9]** \n",
    "1. Allows us to pick up on morphological features that word-level embeddings could miss,\n",
    "2.  we can form a valid representation even for out-of-vocabulary words, which is a huge win\n",
    "\n",
    "**Convolutional Neural Network** as Embadding layer has two primary benefits**[REF6]** :\n",
    "1. allows us to pick up on n-gram features that build more powerful representations,\n",
    "2. More a compact represntation,\n",
    "3. out-of-vocabulary words can be handled. \n",
    "\n",
    "**The highway network layers** allow for smoother information transfer through the input.**[REF9]** \n",
    "\n",
    "\n",
    "**[REF9]** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"7\" style=\"width:50%;height:30px;border: 4px solid black;background-color:#B35900;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h5> Trensformas Character embeddings: </h5>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Review-paper001 (Character-Aware,Character-level).ipynb**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character-level CNN follow steps below: **[REF1]**\n",
    "\n",
    "1. $Q ∈ \\mathbb{R}^{d×d}$ be the matrix character embeddings.$d$ be the dimen- sionality of character embeddings\n",
    "2. $W$ be a Vocabulary that makes  from $l$ dimensional characther Embadding. \n",
    "3. A tagert Word ($W_{k}$) is made up of a sequense of character $[c_1, ... , c_l]$.\n",
    "4. The character-level represention of $W_{k}$, is given by matrix $C^k \\in \\mathbb{R}^{d\\times l}$ (d:number of rows,l:number of columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://image.slidesharecdn.com/cnnsandnlp-180313174154/95/convolutional-neural-networks-and-natural-language-processing-37-638.jpg?cb=1541784206\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"8\" style=\"width:50%;height:30px;border: 4px solid black;background-color:#8800CC;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h5> Convolutional Neural Network: </h5>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is disctibe in <font color=\"blue\">**Medium_NLP 004 (CNN in NLP).ipynb**</font> for NLP and <font color=\"blue\">**Chapter 004- keras(first convolutional neural network, picture_prossing ).ipynb**</font>  for picture classfication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:<br>\n",
    "\n",
    "<div style=\"height:130px;border:3px solid #661100;padding:12px\">\n",
    "<div style=\"position:absolute\">\n",
    "$G_{matrix}=\\begin{pmatrix}\n",
    "A_{11} & B_{12} & C_{13} \\\\\n",
    "A_{21} & B_{22} & C_{23} \\\\\n",
    "A_{31} & B_{32} & C_{33}\\\\\n",
    "\\vdots  & \\vdots & \\vdots \\\\\n",
    "A_{l1} & B_{l2} & C_{l3}\\\\\n",
    " \\end{pmatrix}$\n",
    "</div> <div style=\"position:absolute;left: 17%;top:50%;color:green;font-weight: bold;\"> and </div>\n",
    "<div style=\"position:absolute;left: 20%;top:39%\"> \n",
    "\n",
    "$ke_{kernel}= \\begin{pmatrix}   \n",
    "K_{11} & K_{12} \\\\\n",
    "K_{11} & K_{12} \\\\\n",
    "\\vdots  & \\vdots \\\\\n",
    "\\end{pmatrix}$  \n",
    "</div><div style=\"position:absolute;left: 35%;top:50%;color:green;font-weight: bold;\"> give a new matrix H : </div>\n",
    "    \n",
    "<div style=\"position:absolute;left: 49%;top:50%\">  \n",
    "$ H = \\begin{pmatrix}   \n",
    "h_{1} & h_{2} \n",
    "\\end{pmatrix}$  \n",
    "</div>  <div style=\"position:absolute;left: 59%;top:50%;color:green;font-weight: bold;\"> That is equal: </div>  \n",
    "<div style=\"position:absolute;left: 69%;top:27%\">      \n",
    "$H = \\begin{pmatrix}   \n",
    "h_{1} = \\displaystyle\\sum_{j}^{l} K_{11}.A_{j1} + \\sum_{j}^{l} K_{12}.B_{j2}    \\\\\n",
    "h_{2} = \\displaystyle\\sum_{j}^{l} K_{12}.B_{j2} + \\sum_{j}^{l} K_{13}.C_{j3} \\\\\n",
    "\\end{pmatrix}$  \n",
    "\n",
    "</div>     \n",
    "</div>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"9\" style=\"width:50%;height:30px;border: 4px solid black;background-color:#006611;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h5> The highway Network Layers: </h5>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(the Highway Networks was descriped <font color=\"blue\">Chapter 012 -Keras(Hghway networks).ipynb</font> and <font color=\"blue\">Review-paper002 (Hghway networks).ipynb</font>)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A highway network is an approach to optimizing networks and increasing their depth.  Highway networks use learned gating mechanisms to regulate information flow, inspired by Long Short-Term Memory (LSTM) recurrent neural networks. The gating mechanisms allow neural networks to have paths for information to follow across different layers (\"information highways\")\n",
    "\n",
    "**[REF11]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a simple layer of dee learning is typically made from **a transform activation funcation** like $f$:\n",
    "\n",
    "### $ y = f(x,w_h,b) $, \n",
    "\n",
    "x as input  and y as output.\n",
    "\n",
    "But **highway Model**additionally **use two other nonliear transform funcations**, such that:\n",
    "\n",
    "### $y = f(x,w_h,b).T(x,w_T)+x.C(x,w_C)$\n",
    "\n",
    "Convolutional highway layers are constructed similar to fully connected layers. Weight-sharing and local receptive fields are utilized for both H and T transforms.**[REF10]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"height:280px;border:3px solid #009999;\">\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*qHf_AHv8yJJsKQok4KS4Jw.png\" style=\"height:280px;border:3px solid #009999;position:absolute\">\n",
    "<div style=\"position:absolute;left:51%;top:0%;padding:3%;width:40%\">\n",
    "\n",
    "Formally, **T(x) is the sigmoid function**:\n",
    "\n",
    "### $T(x,w_T,b_T) = \\sigma (w_T^T x+b_T)$\n",
    "\n",
    "That\n",
    "\n",
    "## $\\sigma(z) = \\frac{1}{1+e^{-z}}$\n",
    "\n",
    "\n",
    "\n",
    "</div>    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"11\" style=\"width:100%;height:70px;border: 4px solid black;background-color:#E6BF00;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h1> Python Code for  ELMo preprocessing msthod <h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"12\" style=\"width:100%;height:70px;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h1> ELMo 0 to 100: <h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Should be complite ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"13\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> Pythorch for elmo:    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #3550B7;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "\n",
    "https://towardsdatascience.com/understanding-bidirectional-rnn-in-pytorch-5bd25a5dd66  \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['BOS', 'How', 'are', 'you', 'EOS']\n",
    "seq_len = len(text)\n",
    "batch_size = 1\n",
    "embedding_size = 1\n",
    "hidden_size = 1\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0990, -0.2374, -1.1803,  0.5425,  1.4784])\n"
     ]
    }
   ],
   "source": [
    "# Initialize Input Sequence Randomly:\n",
    "random_input = Variable(torch.FloatTensor(seq_len, batch_size, embedding_size).normal_(), requires_grad=False)\n",
    "print(random_input[:, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Bidirectional GRU Layer\n",
    "bi_grus = torch.nn.GRU(input_size=1, hidden_size=1, num_layers=1, batch_first=False, bidirectional=True)\n",
    "reverse_gru = torch.nn.GRU(input_size=1, hidden_size=1, num_layers=1, batch_first=False, bidirectional=False)\n",
    "#bi_rnn = torch.nn.RNN( input_size=embedding_size, hidden_size=hidden_size, num_layers=1, batch_first=False, bidirectional=True)\n",
    "#bi_output, bi_hidden = bi_rnn(random_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_gru.weight_ih_l0 = bi_grus.weight_ih_l0_reverse\n",
    "reverse_gru.weight_hh_l0 = bi_grus.weight_hh_l0_reverse\n",
    "reverse_gru.bias_ih_l0 = bi_grus.bias_ih_l0_reverse\n",
    "reverse_gru.bias_hh_l0 = bi_grus.bias_hh_l0_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed Input Sequence into Both Networks\n",
    "bi_output, bi_hidden = bi_grus(random_input)\n",
    "reverse_output, reverse_hidden = reverse_gru(random_input[np.arange(4, -1, -1), :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5547, 0.5771, 0.2205, 0.2668, 0.1116], grad_fn=<SelectBackward>)\n",
      "tensor([0.5547, 0.5771, 0.2205, 0.2668, 0.1116], grad_fn=<SelectBackward>)\n",
      "Check Hidden States:\n",
      "tensor([[0.1116]], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# ckeck:\n",
    "print(reverse_output[:, 0, 0])\n",
    "\n",
    "\n",
    "# Check Hidden States\n",
    "print('Check Hidden States:')\n",
    "print(bi_hidden[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stagger\n",
    "forward_output, backward_output = bi_output[:-2, :, :hidden_size], bi_output[2:, :, hidden_size:]\n",
    "staggered_output = torch.cat((forward_output, backward_output), dim=-1)\n",
    "\n",
    "linear = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "# only predict on words\n",
    "labels = random_input[1:-1]\n",
    "\n",
    "# for language models, use cross-entropy :)\n",
    "loss = nn.MSELoss()\n",
    "output = loss(linear(staggered_output), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5446, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"14\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> Use TF-hub of google for elmo:    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #3550B7;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "\n",
    "https://tfhub.dev/google/elmo/2\n",
    "    \n",
    "https://tfhub.dev/google/elmo/2    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This modules supports inputs both in the form of raw text strings (sentenses) or tokenized text strings (list of words).<br>\n",
    "The module outputs fixed embeddings at each LSTM layer, a learnable aggregation of the 3 layers, and a fixed mean-pooled vector representation of the input.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "The output dictionary contains:\n",
    "\n",
    "- **word_emb**: the character-based word representations with shape [batch_size, max_length, **512**].\n",
    "- **lstm_outputs1**: the first LSTM hidden state with shape [batch_size, max_length, **1024**].\n",
    "- **lstm_outputs2**: the second LSTM hidden state with shape [batch_size, max_length, **1024**].\n",
    "- **elmo**: the weighted sum of the 3 layers, where the weights are trainable. This tensor has shape [batch_size, max_length, **1024**]\n",
    "- **default**: a fixed mean-pooling of all contextualized word representations with shape [batch_size, **1024**].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "embeddings = elmo(\n",
    "    [\"the cat is on the mat\", \"dogs are in the fog\"],\n",
    "    signature=\"default\",\n",
    "    as_dict=True)[\"word_emb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"15\" style=\"width:100%;height:70px;border: 4px solid black;background-color:#E6BF00;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h1> ELMo <h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599999 entries, 0 to 1599998\n",
      "Data columns (total 3 columns):\n",
      "created_at    1599999 non-null object\n",
      "text          1599999 non-null object\n",
      "label         1599999 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 36.6+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = \"/Users/apple/Documents/Programming/pyfile/DataBase/project_data/Third__CLean_training.1600000.process.csv\"\n",
    "data_one = pd.read_csv(path)\n",
    "data_one['text'] = data_one['text'].apply(lambda x: re.sub('-PRON- ','',str(x)))\n",
    "data_one.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = data_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:70px;border: 4px solid black;background-color:#E6BF00;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h1> ELMo,TF_hub_embadding, mypakage <h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one of pakage that I write for elmo is TF_hub_embadding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"16\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> my pakage for Elmo (Elmo_Thrones): </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from farhad.Farhadcolor import tcolors,bcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Universal_AWS():\n",
    "    \"\"\"\n",
    "    https://tfhub.dev/s?module-type=text-embedding\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __englishurl__(self):\n",
    "        self.universal_sentence_encoder512 = \"https://tfhub.dev/google/universal-sentence-encoder/2\"\n",
    "        self.universal_sentence_encoder_large512 = \"https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed\"\n",
    "        \n",
    "        self.nnlm_en_dim128 = \"https://tfhub.dev/google/nnlm-en-dim128/1\"\n",
    "        self.nnlm_en_dim128_with_normalization = \"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/1\"\n",
    "        self.random_nnlm_en_dim128 = \"https://tfhub.dev/google/random-nnlm-en-dim128/1\"\n",
    "        \n",
    "        \n",
    "        self.nnlm_en_dim50_with_normalization = \"https://tfhub.dev/google/nnlm-en-dim50-with-normalization/1\"\n",
    "        self.nnlm_en_dim50 = \"https://tfhub.dev/google/nnlm-en-dim50/1\"\n",
    "        self.Elmo_ = \"https://tfhub.dev/google/elmo/2\"\n",
    "        \n",
    "    def __info__(self,mode=('dim512' or 'dim128' or 'dim50')):\n",
    "        info = {}\n",
    "        info['dim512']=\"\"\"\n",
    "        The encoder takes as input a lowercased PTB tokenized string and outputs\n",
    "        a 512 dimensional vector as the sentence embedding. \n",
    "        -------------------------------------------------\n",
    "        input: \n",
    "            dataframe of text\n",
    "        -------------------------------------------------\n",
    "        output: \n",
    "            embadding lsit of string in 512 dimensional\n",
    "        -------------------------------------------------\n",
    "        https://tfhub.dev/google/universal-sentence-encoder/2\n",
    "        https://tfhub.dev/google/universal-sentence-encoder-large/3\n",
    "        https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed\n",
    "        !curl -L \"https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed\" | \n",
    "                                                              tar -zxvC sentence_wise_email/module/module_useT\n",
    "        \"\"\"\n",
    "        \n",
    "        info['dim128']=\"\"\"\n",
    "        The encoder takes as input a lowercased PTB tokenized string and outputs \n",
    "        a 128 dimensional vector as the sentence embedding. \n",
    "        -------------------------------------------------\n",
    "        input: \n",
    "            dataframe of text\n",
    "        -------------------------------------------------\n",
    "        output: \n",
    "            embadding lsit of string in 128 dimensional\n",
    "        -------------------------------------------------\n",
    "        https://tfhub.dev/google/nnlm-en-dim128/1\n",
    "        https://tfhub.dev/google/nnlm-en-dim128-with-normalization/1\n",
    "        https://tfhub.dev/google/random-nnlm-en-dim128/1\n",
    "        !curl -L \"https://tfhub.dev/google/nnlm-id-dim128-with-normalization/1?tf-hub-format=compressed\" | \n",
    "                                                                   tar -zxvC sentence_wise_email/module/module_useT2\n",
    "        \"\"\"\n",
    "        \n",
    "        info['dim50']=\"\"\"\n",
    "        The encoder takes as input a lowercased PTB tokenized string and outputs \n",
    "        a 50 dimensional vector as the sentence embedding. \n",
    "        -------------------------------------------------\n",
    "        input: \n",
    "             dataframe of text\n",
    "        -------------------------------------------------\n",
    "        output: \n",
    "            embadding lsit of string in 50 dimensional\n",
    "        -------------------------------------------------\n",
    "        https://tfhub.dev/google/nnlm-de-dim50-with-normalization/1\n",
    "        https://tfhub.dev/google/nnlm-en-dim50/1\n",
    "        \"\"\"\n",
    "        \n",
    "        print(info[mode])\n",
    "        \n",
    "    def __Embeddding__(self,module):        \n",
    "        with tf.Graph().as_default():\n",
    "            sentences = tf.placeholder(tf.string)\n",
    "            self.embed = hub.Module(module)\n",
    "            self.embeddings = self.embed(sentences)\n",
    "            self.session = tf.train.MonitoredSession()\n",
    "            return lambda x: self.session.run(self.embeddings, {sentences: x})\n",
    "    def __url__(self):\n",
    "        self.__englishurl__()\n",
    "        self.url_dictionary={}\n",
    "        self.url_dictionary['dim512'],self.url_dictionary['dim128'],self.url_dictionary['dim50'] = {},{},{}\n",
    "        \n",
    "        \n",
    "        self.url_dictionary['dim512']['norm'] = [self.universal_sentence_encoder_large512,\n",
    "                                        \"a 512 dimensional vector as the sentence embedding. \"]\n",
    "        self.url_dictionary['dim128']['norm'] = [self.nnlm_en_dim128_with_normalization,\n",
    "                                         \"a 128 dimensional vector as the sentence embedding.\"]\n",
    "        self.url_dictionary['dim50']['norm']  = [self.nnlm_en_dim50_with_normalization,\n",
    "                                        \"a 50 dimensional vector as the sentence embedding.\"]\n",
    "        \n",
    "        self.url_dictionary['dim512']['Neural'] = [self.universal_sentence_encoder512,\n",
    "                                        \"a 512 dimensional vector as the sentence embedding. \"]\n",
    "        self.url_dictionary['dim128']['Neural'] = [self.nnlm_en_dim128,\n",
    "                                         \"a 128 dimensional vector as the sentence embedding.\"]\n",
    "        self.url_dictionary['dim50']['Neural']  = [self.nnlm_en_dim50,\n",
    "                                        \"a 50 dimensional vector as the sentence embedding.\"]\n",
    "        \n",
    "        self.url_dictionary['Elmo']['Elmo']  = [self.Elmo_,\n",
    "                                        \"a 1024 dimensional vector as the sentence embedding.\"]\n",
    "        \n",
    "    def Universal_Encoder(self,df,mode=('dim512' or 'dim128' or 'dim50' or 'Elmo'),kind=\"norm\"):\n",
    "        #if kind!='norm' or kind!='Neural':\n",
    "            #return print(tcolors.RED,\"You should choose norm or Neural for kind\",tcolors.ENDC)\n",
    "            \n",
    "        self.__url__()\n",
    "        embed_fn = self.__Embeddding__(self.url_dictionary[str(mode)][str(kind)][0])\n",
    "        print(tcolors.GREEN+self.url_dictionary[str(mode)][str(kind)][1]+tcolors.ENDC)\n",
    "        self.data = embed_fn(df)\n",
    "        return self.data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"17\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> simple data: </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test = [\n",
    "    \"An examination of our dietary choices and the food we put in our bodies. Based on Jonathan Safran Foer's memoir.\", # Documentary\n",
    "    \"A teenager tries to survive the last week of her disastrous eighth-grade year before leaving to start high school.\", # Comedy\n",
    "    \"Ethan Hunt and his IMF team, along with some familiar allies, race against time after a mission gone wrong.\", # Action, Adventure\n",
    "    'trump tusk tesla'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed'.\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed: 40.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed: 80.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed: 110.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed: 140.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed: 170.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed: 210.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed: 250.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed: 300.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed: 350.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed: 400.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed: 450.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed: 510.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed: 560.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed: 600.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed: 670.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed: 740.00MB\n",
      "INFO:tensorflow:Downloading https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed: 800.00MB\n",
      "INFO:tensorflow:Downloaded https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed, Total size: 810.60MB\n",
      "INFO:tensorflow:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder-large/3?tf-hub-format=compressed'.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\u001b[92ma 128 dimensional vector as the sentence embedding.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "elmo = Universal_AWS()\n",
    "embed = elmo.Universal_Encoder(raw_test,mode='dim512', mode='norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06221409,  0.05603626, -0.00758656, ..., -0.05484381,\n",
       "         0.06425658, -0.04704415],\n",
       "       [-0.03078462,  0.05258544, -0.00985857, ..., -0.04589255,\n",
       "         0.00523193,  0.00101314],\n",
       "       [-0.00207842,  0.02807096,  0.02267872, ...,  0.04572437,\n",
       "        -0.04024108, -0.01628461]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\u001b[92ma 50 dimensional vector as the sentence embedding.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "elmo = Universal_AWS()\n",
    "embed = elmo.Universal_Encoder(raw_test,mode='dim50', kind='norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"18\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> my really data: </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Price_label(0,1)</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>trump tusk tesla</td>\n",
       "      <td>1</td>\n",
       "      <td>trump tusk tesla</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>tesla elon musk may trouble e c want -PRON- ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>tesla elon musk may trouble want hold contempt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>year people find tesla teleportation achieve y...</td>\n",
       "      <td>0</td>\n",
       "      <td>year people find tesla teleportation achieve y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>look mx efficient compare audi jaguar</td>\n",
       "      <td>0</td>\n",
       "      <td>look mx efficient compare audi jaguar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-14</td>\n",
       "      <td>tesla musk risk contempt charge sec argue twee...</td>\n",
       "      <td>1</td>\n",
       "      <td>tesla musk risk contempt charge sec argue twee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_at  ... label\n",
       "0  2010-06-29  ...     1\n",
       "1  2010-06-29  ...     1\n",
       "2  2010-07-01  ...     0\n",
       "3  2010-07-02  ...     0\n",
       "4  2010-07-14  ...     1\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trump tusk tesla'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [s for s in df_data.text[0:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"An examination of our dietary choices and the food we put in our bodies. Based on Jonathan Safran Foer's memoir.\",\n",
    "    'trump tusk tesla',\n",
    "        \"A teenager tries to survive the last week of her disastrous eighth-grade year before leaving to start high school.\", # Comedy\n",
    "    \"Ethan Hunt and his IMF team, along with some familiar allies, race against time after a mission gone wrong.\",\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword argument repeated (<ipython-input-103-ecd8912c5eed>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-103-ecd8912c5eed>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    embed = elmo.Universal_Encoder(test,mode='dim50',mode='norm')\u001b[0m\n\u001b[0m                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword argument repeated\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "#df = df_data.text\n",
    "elmo = ELMO_AWS()\n",
    "embed = elmo.Universal_Encoder(test,mode='dim50',kind='norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2816\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "print(len(embed))\n",
    "print(len(embed[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"19\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> my pakage: </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from farhad.Elmo_Thrones import ELMO_AWS #Universal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword argument repeated (<unknown>, line 3)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3267\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-3-4195c042b0a4>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    get_ipython().run_cell_magic('time', '', \"df = df_data.text[:40]\\nelmo = ELMO_AWS()\\nembed = elmo.Universal_Encoder(df,mode='dim50',mode='norm')\\n\\nprint(len(embed))\\nprint(len(embed[1]))\\n\")\n",
      "  File \u001b[1;32m\"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2323\u001b[0m, in \u001b[1;35mrun_cell_magic\u001b[0m\n    result = fn(magic_arg_s, cell)\n",
      "  File \u001b[1;32m\"<decorator-gen-62>\"\u001b[0m, line \u001b[1;32m2\u001b[0m, in \u001b[1;35mtime\u001b[0m\n",
      "  File \u001b[1;32m\"/anaconda3/lib/python3.6/site-packages/IPython/core/magic.py\"\u001b[0m, line \u001b[1;32m187\u001b[0m, in \u001b[1;35m<lambda>\u001b[0m\n    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \u001b[1;32m\"/anaconda3/lib/python3.6/site-packages/IPython/core/magics/execution.py\"\u001b[0m, line \u001b[1;32m1235\u001b[0m, in \u001b[1;35mtime\u001b[0m\n    expr_ast = self.shell.compile.ast_parse(expr)\n",
      "\u001b[0;36m  File \u001b[0;32m\"/anaconda3/lib/python3.6/site-packages/IPython/core/compilerop.py\"\u001b[0;36m, line \u001b[0;32m100\u001b[0;36m, in \u001b[0;35mast_parse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, symbol, self.flags | PyCF_ONLY_AST, 1)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword argument repeated\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = df_data.text[:40]\n",
    "elmo = ELMO_AWS()\n",
    "embed = elmo.Universal_Encoder(df,mode='dim50',mode='norm')\n",
    "\n",
    "print(len(embed))\n",
    "print(len(embed[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"20\" style=\"width:100%;height:40px;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> : </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dask_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_ml.cluster\n",
    "from sklearn.externals import joblib\n",
    "with joblib.parallel_backend('dask'):\n",
    "    grid_search.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
