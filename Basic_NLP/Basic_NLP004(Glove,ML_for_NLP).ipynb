{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:100px;text-align:center;border: 4px solid black;background-color:#E6BF00;color:white\">\n",
    "\n",
    "<header style=\"width:100%;height:100px;\">\n",
    "  <h1><b> Session 003</b></h1>\n",
    "    <h4> Basic Natural language processing </h4>\n",
    "</header>\n",
    "\n",
    "<div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='border: 4px solid #E6BF00;padding:9px;'>\n",
    "\n",
    "By: Farhad Shadmand \n",
    "    \n",
    "https://github.com/farhadsh1992\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #3550B7;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "\n",
    "glove: https://www.kaggle.com/eswarbabu88/toxic-comment-glove-logistic-regression\n",
    "    \n",
    "<hr>\n",
    "\n",
    "http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/\n",
    "  \n",
    "https://towardsdatascience.com/using-scikit-learn-to-find-bullies-c47a1045d92f\n",
    "    \n",
    "https://www.kaggle.com/eswarbabu88/toxic-comment-glove-logistic-regression\n",
    "    \n",
    "https://www.kaggle.com/stacykurnikova/using-glove-embedding\n",
    "    \n",
    "https://www.kaggle.com/ankitswarnkar/word-embedding-using-glove-vector\n",
    "    \n",
    "https://textminingonline.com/getting-started-with-word2vec-and-glove-in-python\n",
    "    \n",
    "https://markhneedham.com/blog/2018/05/19/interpreting-word2vec-glove-embeddings-sklearn-neo4j-graph-algorithms/\n",
    "    \n",
    "http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/\n",
    "    \n",
    "https://radimrehurek.com/gensim/sklearn_api/w2vmodel.html\n",
    "    \n",
    "https://www.kaggle.com/reiinakano/basic-nlp-bag-of-words-tf-idf-word2vec-lstm\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:70px;border: 4px solid black;background-color:#E6BF00;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h1> Glove <h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import punkt  # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2816 entries, 1 to 3274\n",
      "Data columns (total 3 columns):\n",
      "created_at          2816 non-null object\n",
      "clean_text          2816 non-null object\n",
      "Price_label(0,1)    2816 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 88.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data_path = '/Users/apple/Documents/Programming/python/Project/data/Clean_tweets/2Tesla_label_from_2010-06-29_to_2019-02-26_2019227.csv'\n",
    "df_data = pd.read_csv(data_path)\n",
    "df_data = df_data.dropna()\n",
    "df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "path_file = '/anaconda3/lib/python3.6/farhad/data/Glove/glove.first-100k.6B.50d.txt'\n",
    "embeddings_index = {}\n",
    "with open(path_file, encoding='UTF8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        try:\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "        except ValueError:\n",
    "            pass\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0234f1d70131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'values' is not defined"
     ]
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2vec(s):\n",
    "    words = str(s).lower()\n",
    "    words = word_tokenize(words)\n",
    "    #words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(embeddings_index[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(100)\n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_glove = [sent2vec(x) for x in df_data.clean_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.1777471e-02,  3.8854595e-02,  1.3073294e-01,  8.8154934e-02,\n",
       "        7.5900324e-02,  6.7043714e-02, -8.8376492e-02, -3.2602184e-02,\n",
       "       -4.5013085e-02,  9.6964978e-02,  5.8779243e-02,  1.0359993e-01,\n",
       "       -5.8047850e-02, -1.3063227e-01,  1.3075033e-01,  1.5174074e-01,\n",
       "       -3.6956672e-02, -1.6907761e-02,  1.7658418e-02, -1.0020012e-01,\n",
       "        2.5143586e-02,  3.2064557e-02,  1.6299194e-01,  2.0805253e-02,\n",
       "        5.5056568e-02, -4.1618153e-01, -6.9847889e-02, -7.7121764e-02,\n",
       "        6.3571259e-02, -1.5618420e-01,  6.6336137e-01,  7.0837297e-02,\n",
       "       -2.2342558e-01, -2.3988081e-02, -7.3592146e-03, -1.7250635e-01,\n",
       "        2.0996990e-02, -1.1576416e-01,  6.3237943e-02,  3.0372256e-02,\n",
       "        5.3108312e-02, -3.3725314e-02, -9.9265322e-02,  1.4586908e-01,\n",
       "        7.8060992e-02, -3.8546309e-02, -4.7269735e-02,  1.4707953e-01,\n",
       "       -3.9680864e-04,  2.1965217e-02], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_glove[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of data: 2816\n",
      "lenght of features: 50 50\n"
     ]
    }
   ],
   "source": [
    "print('Lenght of data:',len(data_glove))\n",
    "print('lenght of features:',len(data_glove[1]),len(data_glove[11]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Better_way:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from farhad.TextAwsome import Text_Embadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "        ------------------------------------------------------------------- \n",
      "\n",
      "        Funcation:\n",
      "        0. model_GLove = Text_Embadding(df.text) \n",
      "        \n",
      "        \n",
      "\u001b[92mChoose one of dicationary below:\u001b[0m\n",
      "        1. model_GLove.Glove_100k_6B_50d()\n",
      "        2. model_GLove.Glove_twitter_27B_25d()\n",
      "        3. model_GLove.Glove_twitter_27B_50d()\n",
      "        \n",
      "\u001b[92mNext:\u001b[0m\n",
      "        4. data_embedding = model_GLove.data2vec()  \n",
      "\n",
      "        or \n",
      "\n",
      "        5. sent_embedding = model_GLove.sent2vec(text) just for a sentences\n",
      "        \n",
      "        \n",
      "\u001b[92mFor saving file:\u001b[0m \n",
      "\n",
      "        6. model_GLove.save_file(name_file_save)\n",
      "\n",
      "        ------------------------------------------------------------------------\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "glove_model = Text_Embadding()\n",
    "glove_model.__info__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_model = Text_Embadding(df_data.clean_text)\n",
    "glove_model.Glove_100k_6B_50d()\n",
    "data_embedding = glove_model.data2vec()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of data: 2816\n",
      "lenght of features: 50 50\n"
     ]
    }
   ],
   "source": [
    "print('Lenght of data:',len(data_embedding))\n",
    "\n",
    "print('lenght of features:',len(data_embedding[1]),len(data_embedding[11]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.1777471e-02,  3.8854595e-02,  1.3073294e-01,  8.8154934e-02,\n",
       "        7.5900324e-02,  6.7043714e-02, -8.8376492e-02, -3.2602184e-02,\n",
       "       -4.5013085e-02,  9.6964978e-02,  5.8779243e-02,  1.0359993e-01,\n",
       "       -5.8047850e-02, -1.3063227e-01,  1.3075033e-01,  1.5174074e-01,\n",
       "       -3.6956672e-02, -1.6907761e-02,  1.7658418e-02, -1.0020012e-01,\n",
       "        2.5143586e-02,  3.2064557e-02,  1.6299194e-01,  2.0805253e-02,\n",
       "        5.5056568e-02, -4.1618153e-01, -6.9847889e-02, -7.7121764e-02,\n",
       "        6.3571259e-02, -1.5618420e-01,  6.6336137e-01,  7.0837297e-02,\n",
       "       -2.2342558e-01, -2.3988081e-02, -7.3592146e-03, -1.7250635e-01,\n",
       "        2.0996990e-02, -1.1576416e-01,  6.3237943e-02,  3.0372256e-02,\n",
       "        5.3108312e-02, -3.3725314e-02, -9.9265322e-02,  1.4586908e-01,\n",
       "        7.8060992e-02, -3.8546309e-02, -4.7269735e-02,  1.4707953e-01,\n",
       "       -3.9680864e-04,  2.1965217e-02], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_embedding[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:70px;border: 4px solid black;background-color:#E6BF00;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h1> LogisticRegression <h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "    classifier = LogisticRegression(solver='sag')\n",
    "\n",
    "    cv_score = np.mean(cross_val_score(classifier, xtrain_glove, train_target, cv=3, scoring='roc_auc'))\n",
    "    scores.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "\n",
    "    classifier.fit(xtrain_glove, train_target)\n",
    "    print('Training LogisticRegression Classifier for {} is complete!!'.format(class_name))\n",
    "    submission[class_name] = classifier.predict_proba(xtest_glove)[:, 1]\n",
    "\n",
    "print('Total CV score is {}'.format(np.mean(scores)))\n",
    "\n",
    "submission.to_csv('submission_glove_LogisticRegression.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wordcloud_I = WordCloud(max_font_size=None, stopwords=stop,scale = 2,colormap = 'Dark2').generate(q_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:70px;border: 4px solid black;background-color:#E6BF00;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h1> ExtraTreesClassifier <h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etree_w2v_tfidf = Pipeline([\n",
    "    (\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v)),\n",
    "    (\"extra trees\", ExtraTreesClassifier(n_estimators=200))])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
