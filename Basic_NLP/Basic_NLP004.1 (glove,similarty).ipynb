{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:100px;text-align:center;border: 4px solid black;background-color:#E6BF00;color:white\">\n",
    "\n",
    "<header style=\"width:100%;height:100px;\">\n",
    "  <h1><b> Session 003</b></h1>\n",
    "    <h4> Basic Natural language processing </h4>\n",
    "</header>\n",
    "\n",
    "<div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='border: 4px solid #E6BF00;padding:9px;'>\n",
    "\n",
    "By: Farhad Shadmand \n",
    "    \n",
    "https://github.com/farhadsh1992\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #3550B7;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "    \n",
    "PyCon APAC 2018: https://www.youtube.com/watch?v=Y8gKX5zMRyQ\n",
    "    \n",
    "PyCon APAC 2018: https://github.com/maciejkula/glove-python\n",
    "    \n",
    "    \n",
    "Glove Vector: https://www.kaggle.com/ankitswarnkar/word-embedding-using-glove-vector\n",
    "    \n",
    "\n",
    "<hr>\n",
    "    \n",
    "\n",
    "  \n",
    "https://towardsdatascience.com/using-scikit-learn-to-find-bullies-c47a1045d92f\n",
    "    \n",
    "https://www.kaggle.com/eswarbabu88/toxic-comment-glove-logistic-regression\n",
    "    \n",
    "https://www.kaggle.com/stacykurnikova/using-glove-embedding\n",
    "    \n",
    "https://www.kaggle.com/ankitswarnkar/word-embedding-using-glove-vector\n",
    "    \n",
    "https://textminingonline.com/getting-started-with-word2vec-and-glove-in-python\n",
    "    \n",
    "https://markhneedham.com/blog/2018/05/19/interpreting-word2vec-glove-embeddings-sklearn-neo4j-graph-algorithms/\n",
    "    \n",
    "http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/\n",
    "    \n",
    "https://radimrehurek.com/gensim/sklearn_api/w2vmodel.html\n",
    "    \n",
    "Great: https://www.kaggle.com/reiinakano/basic-nlp-bag-of-words-tf-idf-word2vec-lstm\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<div style=\"border: 4px solid #3550B7;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "\n",
    "(1) https://github.com/maciejkula/glove-python\n",
    "    \n",
    "(2) https://www.youtube.com/watch?v=Y8gKX5zMRyQ\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:70px;border: 4px solid black;background-color:#E6BF00;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h1>  <h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:40px;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> : </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:40px;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> Theory: </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $ Similarity(u, v) = \\frac{u.v}{|u|^2.|v|^2}= cos(\\theta) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:70px;border: 4px solid black;background-color:#E6BF00;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h1> python code (glove pakage:)<h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:40px;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> made my model (dictionary): </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 4px solid #3550B7;background-color:#BFE6FF;color:black;border-radius: 5px;padding:7px\">\n",
    "  <strong> Refrence: </strong><br>\n",
    "    \n",
    "PyCon APAC 2018: https://www.youtube.com/watch?v=Y8gKX5zMRyQ\n",
    "    \n",
    "PyCon APAC 2018: https://github.com/maciejkula/glove-python\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glove import Glove\n",
    "from glove import Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(filename):\n",
    "    \"\"\"\n",
    "    Read corpus from regular text file \n",
    "    \"\"\"\n",
    "    \n",
    "    delchars = [chr(c) for c in range(256)]\n",
    "    delchars = [x for x in delchars if not x.isalnum() ] \n",
    "    delchars.remove(' ')\n",
    "    delchars = ''.join(delchars)\n",
    "    table = str.maketrans(dict.fromkeys(delchars))\n",
    "    with open(filename, 'r') as datafile:\n",
    "        for line in datafile:\n",
    "            yield line.lower().translate(table).split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = path\n",
    "get_data = read_corpus(file_path)\n",
    "corpus_model = Corpus()\n",
    "corpus_model.fit(get_data, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =10\n",
    "no_threads = 8\n",
    "\n",
    "glove = Glove(no_components=100, learning_rate=0.05)\n",
    "glove.fit(corpus_model.matrix, epochs=epochs, no_threads=no_threads, verbose=True)\n",
    "glove.add_dictionary(corpus_model.dictionary)\n",
    "\n",
    "# glove.save('model/articles_glove.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove.most_similar('tesla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model:\n",
    "glove.save('model/articles_glove.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model:\n",
    "from glove import Glove\n",
    "glove = Glove()\n",
    "glove = glove.load('model/articles_glove.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:40px;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> used pre-existing model (by Stanfors university) : </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glove import Glove\n",
    "glove = Glove()\n",
    "\n",
    "path_file = '/anaconda3/lib/python3.6/farhad/data/Glove/glove.first-100k.6B.50d.txt'\n",
    "stanford = glove.load_stanford(path_file )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.95897  ,  0.86149  , -0.53064  , -0.19908  ,  0.42945  ,\n",
       "        0.93177  ,  0.067319 , -0.21413  ,  0.39488  , -0.53561  ,\n",
       "        0.42881  , -1.3334   , -0.038192 , -0.15667  ,  0.94351  ,\n",
       "       -0.21873  , -0.15586  ,  0.084439 , -0.058604 , -0.55145  ,\n",
       "       -0.53281  ,  1.2434   ,  0.63441  ,  0.79234  ,  0.0097936,\n",
       "       -1.7124   , -0.77291  , -1.0024   , -0.69472  , -0.50487  ,\n",
       "        3.0517   ,  1.4981   , -0.32957  , -0.53871  , -0.21201  ,\n",
       "       -0.14259  , -0.02706  ,  0.5858   , -0.56642  , -0.55984  ,\n",
       "       -0.60905  , -0.57062  ,  1.3338   ,  0.67097  ,  1.0643   ,\n",
       "       -0.4181   , -0.44273  , -1.0158   , -0.35795  , -0.31111  ])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanford.word_vectors[stanford.dictionary['women']][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('volt', 0.6956429105311589),\n",
       " ('westinghouse', 0.678256119091891),\n",
       " ('ev1', 0.6599545102145767),\n",
       " ('sandisk', 0.6567678114984614)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stanford.most_similar('tesla')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;height:40px;border: 4px solid black;background-color:#AB274F;color:white;text-align:center;border-radius: 25px;padding:3px\">\n",
    "    <h4> most-similarty for psotive and negtive: </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = stanford.dictionary\n",
    "w = stanford.word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def most_similar(positive, negtive,dictionary,word_vectors , topn=10, freq_thersold=5, ):\n",
    "    \"\"\"\n",
    "    build a mean vector model for the give positive and negtive terms,\n",
    "    \"\"\"\n",
    "    vocab = dictionary\n",
    "    w = word_vectors\n",
    "    \n",
    "    mean_vecs = []\n",
    "    id2word = [i for i in vocab.keys()]\n",
    "    \n",
    "    \n",
    "    for word in positive: mean_vecs.append(w[vocab[word]])\n",
    "    for word in negtive: mean_vecs.append(-1* w[vocab[word]])\n",
    "    \n",
    "    mean = np.array(mean_vecs).mean(axis=0)\n",
    "    mean /= np.linalg.norm(mean)\n",
    "    \n",
    "    # Now calculate cosine distance between this mean vector and all others,\n",
    "    dists = np.dot(w, mean)\n",
    "    \n",
    "    best = np.argsort(dists)[::-1][:topn + len(positive) +len(negtive)+100]\n",
    "    \n",
    "    \n",
    "    result = [(id2word[i], dists[i]) for i in  best if (vocab[id2word[i]] >= freq_thersold and id2word[i] not in positive and id2word[i] not in negtive) ]\n",
    "     \n",
    "    return result[:topn]                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chinese', 4.065346967035199),\n",
       " ('japanese', 3.970867835179218),\n",
       " ('foreign', 3.7693251347971493),\n",
       " ('czech', 3.749297004412022),\n",
       " ('russia', 3.746145445946273),\n",
       " ('taiwanese', 3.716722490262971),\n",
       " ('german', 3.6878480481609417),\n",
       " ('ukrainian', 3.6062288548171355),\n",
       " ('european', 3.527507755596246),\n",
       " ('finnish', 3.5249538328605454)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(['russian','american'],['war'],dictionary=stanford.dictionary, word_vectors=stanford.word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('german', 3.961287223593513),\n",
       " ('japanese', 3.9499414022393626),\n",
       " ('text-type', 3.8346648728737223),\n",
       " ('soviet', 3.8329801129055836),\n",
       " ('fathur', 3.818407209437988),\n",
       " ('canoer', 3.7234466761011618),\n",
       " ('chinese', 3.5695524642469167),\n",
       " ('czech', 3.5388879579641332),\n",
       " ('french', 3.3997469229835415),\n",
       " ('russia', 3.342279069684272)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(['russian','american'],['peace'],dictionary=stanford.dictionary, word_vectors=stanford.word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('emperor', 3.6891035906826324),\n",
       " ('kingdom', 3.682609648479754),\n",
       " ('countries', 3.43808011735338),\n",
       " ('throne', 3.315667627092976),\n",
       " ('queen', 3.267751074080608),\n",
       " ('25-64', 3.2573677706189974),\n",
       " ('attend', 3.1857437394212695),\n",
       " ('ceremonies', 3.1813367776565586),\n",
       " ('ii', 3.1684167116686144),\n",
       " ('china', 3.1377966552185512)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(['king','women'],['man'],dictionary=stanford.dictionary, word_vectors=stanford.word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
